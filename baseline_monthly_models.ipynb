{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import datetime\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import aggregator as ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_name_review = \"distributed_data_collection/databases/review_data_sample.csv\"\n",
    "data_file_name_book = \"distributed_data_collection/databases/book_data_sample.csv\"\n",
    "\n",
    "#data_file_name_review = \"distributed_data_collection/databases/review_data.csv\"\n",
    "#data_file_name_book = \"distributed_data_collection/databases/book_data.csv\"\n",
    "\n",
    "start_date = datetime.datetime(2018, 1, 1)\n",
    "end_date = datetime.datetime(2020, 11, 29)\n",
    "\n",
    "book_columns = [\"num_reviews\", \"num_ratings\", \"avg_rating\"] ##THIS IS BASELINE\n",
    "#book_columns = [\"num_reviews\", \"num_ratings\", \"avg_rating\", \"book_language\", \"series\", \"book_author\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically, we could test against multiple grains (ie, day, week, month, quarter). However, I am only working with month. I ruled out the quarterly grain because it wouldn't include enough 2020 time periods to observe a trend in model performance over time. Then because the maximum monthly review counts were in the seventies, I didn't feel I could split those further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregator Initiated.\n",
      "Processing Scraper Output...\n",
      "Scraper Output Processed.\n",
      "Aggregating Review Data...\n",
      "Review Data Aggregated.\n",
      "Merging Book Data...\n",
      "Book Data Merged.\n"
     ]
    }
   ],
   "source": [
    "data_aggregator = ag.Aggregator(data_file_name_review, data_file_name_book, book_columns, start_date, end_date, \"month\")\n",
    "data = data_aggregator.aggregate(\"by_book\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process will take all the 2018-2019 periods as features and will use those to predict reviews for each 2020 period. Differences in the overall accuracy of each model as well as shifts in the importance of different features to the model may indicate COVID-related change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_periods_post = []\n",
    "\n",
    "for col in data.columns:\n",
    "    if \"review_count\" in col:\n",
    "        if \"2020\" in col:\n",
    "            time_periods_post.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to use the same test/train split for every time period, so I need to make the split before selecting which period will be the feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_train = 0.75\n",
    "\n",
    "data = data.iloc[np.random.permutation(data.index)].reset_index(drop=True) #SHUFFLES DATA\n",
    "\n",
    "num_observations_total = len(data)\n",
    "num_observations_train = int(num_observations_total* perc_train)\n",
    "num_observations_test = num_observations_total - num_observations_train\n",
    "\n",
    "data_train = data.head(num_observations_train).reset_index(drop = True)\n",
    "data_test = data.tail(num_observations_test).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to iterate through: logorithmic transformation of label and the kind of model used. Eventually, will want to add alpha values and other book meta-data fields.\n",
    "\n",
    "For the moment, I am turning logorithmic transformation off. It's pretty clear that it has no impact, and I don't want to keep running it while I experiment with other aspects of the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_types_list = [(\"linear\", LinearRegression()), (\"ridge\", Ridge(normalize = True)), (\"lasso\",Lasso(normalize = True))]\n",
    "is_log_options = [False, True]\n",
    "#regression_types_list = [(\"linear\", LinearRegression())] ##THIS IS BASELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here goes on modeling! We will select the best model for each time period based on MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/42 models processed\n",
      "10/42 models processed\n",
      "15/42 models processed\n",
      "20/42 models processed\n",
      "25/42 models processed\n",
      "30/42 models processed\n",
      "35/42 models processed\n",
      "40/42 models processed\n",
      "42/42 models processed\n"
     ]
    }
   ],
   "source": [
    "#JUST FOR PROGRESS PRINTING\n",
    "\n",
    "num_models = len(regression_types_list)\n",
    "num_periods = len(time_periods_post)\n",
    "num_is_log_options = len(is_log_options)\n",
    "num_models_total = num_periods *num_models * num_is_log_options\n",
    "num_models_complete = 0\n",
    "\n",
    "#ACTUAL MODELING\n",
    "performance_df = pd.DataFrame(columns = [\"post_period\", \"regression_type\", \"mse_train\", \"mse_test\", \"r2_train\", \"r2_test\"])\n",
    "\n",
    "for i in range(len(time_periods_post)): #ITERATE OVER EACH PERIOD IN THE POST PERIOD\n",
    "    \n",
    "    label = time_periods_post[i]\n",
    "    \n",
    "    data_train_period = data_train.copy()\n",
    "    data_test_period = data_test.copy()\n",
    "    \n",
    "    #REMOVE OTHER POST-PERIODS FROM DATA \n",
    "    \n",
    "    for post_period in time_periods_post:\n",
    "\n",
    "        if post_period != label:\n",
    "            data_train_period.drop(columns = post_period, inplace = True)\n",
    "            data_test_period.drop(columns = post_period, inplace = True)\n",
    "                   \n",
    "    #CREATE TRAINING & TESTING DATA SPECIFIC TO THAT PERIOD \n",
    "\n",
    "    x_train, y_train = data_train_period.drop(label,1), data_train_period[label]\n",
    "    x_test, y_test = data_test_period.drop(label,1), data_test_period[label]\n",
    "        \n",
    "    optimal_model = None\n",
    "    optimal_regression_type = None\n",
    "    optimal_mse_test = None\n",
    "    optimal_is_log = None\n",
    "    is_none = True\n",
    "    \n",
    "    for tup in regression_types_list:\n",
    "        for is_log in is_log_options:\n",
    "            \n",
    "            regression_type, model = tup[0], tup[1]\n",
    "\n",
    "            model.fit(x_train, y_train)\n",
    "            mse_test = metrics.mean_squared_error(y_test, model.predict(x_test))\n",
    "\n",
    "            if is_first:\n",
    "                optimal_model = model\n",
    "                optimal_mse_test = mse_test\n",
    "                optimal_regression_type = regression_type\n",
    "                optimal_is_log = is_log\n",
    "                \n",
    "                is_none = False\n",
    "\n",
    "            elif mse_test < optimal_mse_test:\n",
    "\n",
    "                optimal_model = model\n",
    "                optimal_mse_test = mse_test\n",
    "                optimal_regression_type = regression_type\n",
    "                optimal_is_log = is_log\n",
    "\n",
    "            #PRINT UPDATES\n",
    "\n",
    "            num_models_complete +=1\n",
    "\n",
    "            if (num_models_complete % 5 == 0) or (num_models_complete == num_models_total):\n",
    "                print(\"{}/{} models processed\".format(num_models_complete, num_models_total))\n",
    "                \n",
    "    #GET METRICS FOR WINNING MODEL\n",
    "    \n",
    "    mse_train = metrics.mean_squared_error(y_test, optimal_model.predict(x_test))\n",
    "    mse_test = metrics.mean_squared_error(y_test, optimal_model.predict(x_test))\n",
    "\n",
    "    r2_train = metrics.r2_score(y_train, optimal_model.predict(x_train))\n",
    "    r2_test = metrics.r2_score(y_test, optimal_model.predict(x_test))\n",
    "        \n",
    "    metric_dict = {\"post_period\": label, \"regression_type\": optimal_regression_type, \"mse_train\": mse_train, \"mse_test\": mse_test, \"r2_train\": r2_train, \"r2_test\": r2_test}\n",
    "    performance_df = performance_df.append(metric_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  post_period regression_type  mse_train  mse_test  r2_train  r2_test\n",
      "0     2020-01           lasso      0.074     0.074       0.0   -0.008\n",
      "1     2020-02           lasso      0.005     0.005       0.0    0.000\n",
      "2     2020-03           lasso      0.002     0.002       0.0    0.000\n",
      "3     2020-04           lasso      0.110     0.110       0.0   -0.039\n",
      "4     2020-05           lasso      0.007     0.007       0.0    0.000\n",
      "5     2020-06           lasso      0.002     0.002       0.0    0.000\n",
      "6     2020-07           lasso      0.039     0.039       0.0   -0.004\n"
     ]
    }
   ],
   "source": [
    "performance_df[\"post_period\"] = performance_df[\"post_period\"].apply(lambda text: text.replace(\"review_count \", \"\"))\n",
    "print(performance_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
