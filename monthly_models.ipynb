{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "import aggregator as ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_file_name_review = \"distributed_data_collection/databases/review_data_sample.csv\"\n",
    "#data_file_name_book = \"distributed_data_collection/databases/book_data_sample.csv\"\n",
    "\n",
    "data_file_name_review = \"distributed_data_collection/databases/review_data.csv\"\n",
    "data_file_name_book = \"distributed_data_collection/databases/book_data.csv\"\n",
    "\n",
    "start_date = datetime.datetime(2018, 1, 1)\n",
    "end_date = datetime.datetime(2020, 11, 29)\n",
    "\n",
    "#book_columns = [\"num_reviews\", \"num_ratings\", \"avg_rating\"] ##THIS IS BASELINE\n",
    "book_columns = [\"num_reviews\", \"num_ratings\", \"avg_rating\", \"book_language\", \"series\", \"book_author\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically, we could test against multiple grains (ie, day, week, month, quarter). However, I am only working with month. I ruled out the quarterly grain because it wouldn't include enough 2020 time periods to observe a trend in model performance over time. Then because the maximum monthly review counts were in the seventies, I didn't feel I could split those further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregator Initiated.\n",
      "Processing Scraper Output...\n",
      "Scraper Output Processed.\n",
      "Aggregating Review Data...\n",
      "Review Data Aggregated.\n",
      "Merging Book Data...\n",
      "Book Data Merged.\n"
     ]
    }
   ],
   "source": [
    "data_aggregator = ag.Aggregator(data_file_name_review, data_file_name_book, book_columns, start_date, end_date, \"month\")\n",
    "data = data_aggregator.aggregate(\"by_book\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to drop binary feature columns which have a small number of values. The linear regression regularization will do a rigorous feature selection, so this step is mostly to reduce the amount of data that it has to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dropped = []\n",
    "k = 2\n",
    "\n",
    "for col in data.columns:\n",
    "    \n",
    "    num_values = data[col].nunique()\n",
    "    \n",
    "    if num_values == 1:\n",
    "        columns_dropped.append(col)\n",
    "        \n",
    "    elif num_values == 2:\n",
    "        if data[col].sum() <=2:\n",
    "            columns_dropped.append(col)\n",
    "            \n",
    "for col in columns_dropped:\n",
    "    data.drop(columns = col, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to get a sense of how many features got dropped. I assume a ton!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10113 columns dropped, 2185 columns remaining\n"
     ]
    }
   ],
   "source": [
    "num_col_dropped = len(columns_dropped)\n",
    "num_col_remaining = len(data.columns)\n",
    "\n",
    "print(\"{} columns dropped, {} columns remaining\".format(num_col_dropped, num_col_remaining))\n",
    "\n",
    "#print(columns_dropped)\n",
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process will take all the 2018-2019 periods as features and will use those to predict reviews for each 2020 period. Differences in the overall accuracy of each model as well as shifts in the importance of different features to the model may indicate COVID-related change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_periods_post = []\n",
    "\n",
    "for col in data.columns:\n",
    "    if \"review_count\" in col:\n",
    "        if \"2020\" in col:\n",
    "            time_periods_post.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to use the same test/train split for every time period, so I need to make the split before selecting which period will be the feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_train = 0.75\n",
    "\n",
    "data = data.iloc[np.random.permutation(data.index)].reset_index(drop=True) #SHUFFLES DATA\n",
    "\n",
    "num_observations_total = len(data)\n",
    "num_observations_train = int(num_observations_total* perc_train)\n",
    "num_observations_test = num_observations_total - num_observations_train\n",
    "\n",
    "data_train = data.head(num_observations_train).reset_index(drop = True)\n",
    "data_test = data.tail(num_observations_test).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to iterate through: logorithmic transformation, regularization type, and alpha value. For the moment, I am turning logorithmic transformation off. It's pretty clear that it has no impact, and I don't want to keep running it while I experiment with other aspects of the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = list(range(1,11))\n",
    "regression_types_list = [\"linear\", \"ridge\", \"lasso\"]\n",
    "\n",
    "#is_log_options = [False, True]\n",
    "is_log_options = [False] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here goes on modeling! We will select the best model for each time period based on MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/231 models processed\n",
      "20/231 models processed\n",
      "30/231 models processed\n",
      "40/231 models processed\n",
      "50/231 models processed\n",
      "60/231 models processed\n",
      "70/231 models processed\n",
      "80/231 models processed\n",
      "90/231 models processed\n",
      "100/231 models processed\n",
      "110/231 models processed\n",
      "120/231 models processed\n",
      "130/231 models processed\n",
      "140/231 models processed\n",
      "150/231 models processed\n",
      "160/231 models processed\n",
      "170/231 models processed\n",
      "180/231 models processed\n",
      "190/231 models processed\n",
      "200/231 models processed\n",
      "210/231 models processed\n",
      "220/231 models processed\n",
      "230/231 models processed\n",
      "231/231 models processed\n"
     ]
    }
   ],
   "source": [
    "#JUST FOR PROGRESS PRINTING\n",
    "\n",
    "num_models = len(regression_types_list)\n",
    "num_periods = len(time_periods_post)\n",
    "num_is_log_options = len(is_log_options)\n",
    "num_alphas = len(alpha_list)\n",
    "\n",
    "num_models_total = (num_periods * num_is_log_options) * ( (num_alphas * (num_models - 1)) + 1)\n",
    "num_models_complete = 0\n",
    "model_dict = {}\n",
    "\n",
    "#ACTUAL MODELING\n",
    "performance_df = pd.DataFrame(columns = [\"post_period\", \"regression_type\", \"is_log\", \"alpha\", \"mse_test\", \"r2_train\", \"r2_test\"])\n",
    "\n",
    "for i in range(len(time_periods_post)): #ITERATE OVER EACH PERIOD IN THE POST PERIOD\n",
    "    \n",
    "    label = time_periods_post[i]\n",
    "    \n",
    "    data_train_period = data_train.copy()\n",
    "    data_test_period = data_test.copy()\n",
    "    \n",
    "    #REMOVE OTHER POST-PERIODS FROM DATA \n",
    "    \n",
    "    for post_period in time_periods_post:\n",
    "\n",
    "        if post_period != label:\n",
    "            data_train_period.drop(columns = post_period, inplace = True)\n",
    "            data_test_period.drop(columns = post_period, inplace = True)\n",
    "                   \n",
    "    #CREATE TRAINING & TESTING DATA SPECIFIC TO THAT PERIOD \n",
    "\n",
    "    x_train, y_train = data_train_period.drop(label,1), data_train_period[label]\n",
    "    x_test, y_test = data_test_period.drop(label,1), data_test_period[label]\n",
    "        \n",
    "    optimal_model = None\n",
    "    optimal_regression_type = None\n",
    "    optimal_mse_test = None\n",
    "    optimal_is_log = None\n",
    "    optimal_alpha = None\n",
    "    is_none = True\n",
    "    \n",
    "    for regression_type in regression_types_list:\n",
    "        for is_log in is_log_options:\n",
    "            for alpha_val in alpha_list:\n",
    "                \n",
    "                if regression_type == \"linear\":\n",
    "                    model = LinearRegression()\n",
    "                    \n",
    "                if regression_type == \"ridge\":\n",
    "                    model = Ridge(normalize = True, alpha = alpha_val) \n",
    "                    \n",
    "                if regression_type == \"lasso\":\n",
    "                    model = Lasso(normalize = True, alpha = alpha_val)\n",
    "            \n",
    "                model.fit(x_train, y_train)\n",
    "                mse_test = metrics.mean_squared_error(y_test, model.predict(x_test))\n",
    "\n",
    "                if is_none:\n",
    "                    optimal_model = model\n",
    "                    optimal_mse_test = mse_test\n",
    "                    optimal_regression_type = regression_type\n",
    "                    optimal_is_log = is_log\n",
    "                    \n",
    "                    if regression_type == \"linear\":\n",
    "                        alpha_val = None\n",
    "                    \n",
    "                    optimal_alpha = alpha_val\n",
    "\n",
    "                    is_none = False\n",
    "\n",
    "                elif mse_test < optimal_mse_test:\n",
    "\n",
    "                    optimal_model = model\n",
    "                    optimal_mse_test = mse_test\n",
    "                    optimal_regression_type = regression_type\n",
    "                    optimal_is_log = is_log\n",
    "                    \n",
    "                    if regression_type == \"linear\":\n",
    "                        alpha_val = None\n",
    "                    \n",
    "                    optimal_alpha = alpha_val\n",
    "\n",
    "                #PRINT UPDATES\n",
    "\n",
    "                num_models_complete +=1\n",
    "\n",
    "                if (num_models_complete % 10 == 0) or (num_models_complete == num_models_total):\n",
    "                    print(\"{}/{} models processed\".format(num_models_complete, num_models_total))\n",
    "                    \n",
    "                if regression_type == \"linear\":\n",
    "                    break\n",
    "                \n",
    "    #GET METRICS FOR WINNING MODEL\n",
    "    \n",
    "    #mse_train = metrics.mean_squared_error(y_train, optimal_model.predict(x_train))\n",
    "    mse_test = metrics.mean_squared_error(y_test, optimal_model.predict(x_test))\n",
    "\n",
    "    r2_train = metrics.r2_score(y_train, optimal_model.predict(x_train))\n",
    "    r2_test = metrics.r2_score(y_test, optimal_model.predict(x_test))\n",
    "        \n",
    "    metric_dict = {\"post_period\": label, \"regression_type\": optimal_regression_type, \"is_log\": optimal_is_log, \"alpha\": optimal_alpha, \"mse_test\": mse_test, \"r2_train\": r2_train, \"r2_test\": r2_test}\n",
    "    performance_df = performance_df.append(metric_dict, ignore_index=True)\n",
    "    model_dict[label] = optimal_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance df captures the overall predictiveness of pre-period data on post-period data. We expect to see declines due to concept drift. Sharp dropoffs in performance might suggest larger changes in reading trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   post_period regression_type is_log alpha  mse_test  r2_train  r2_test\n",
      "0      2020-01           ridge  False     1     3.587     0.807    0.744\n",
      "1      2020-02           ridge  False     1     2.025     0.729    0.654\n",
      "2      2020-03           ridge  False     1     2.259     0.718    0.642\n",
      "3      2020-04           ridge  False     1     3.710     0.768    0.703\n",
      "4      2020-05           ridge  False     1     4.188     0.715    0.615\n",
      "5      2020-06           ridge  False     1     4.042     0.620    0.568\n",
      "6      2020-07           ridge  False     2     3.486     0.616    0.570\n",
      "7      2020-08           ridge  False     1     2.330     0.646    0.594\n",
      "8      2020-09           ridge  False     2     2.367     0.587    0.525\n",
      "9      2020-10           ridge  False     3     1.501     0.519    0.414\n",
      "10     2020-11           ridge  False     5     0.018     0.085    0.029\n"
     ]
    }
   ],
   "source": [
    "performance_df[\"post_period\"] = performance_df[\"post_period\"].apply(lambda text: text.replace(\"review_count \", \"\"))\n",
    "print(performance_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where it's really at! Understanding what features are most important to each model can help us understand the drivers of reading in each period. Right now, the features aren't normalized, meaning it's valid to compare the variation of each feature coefficient across time periods, but it isn't valid to compare feature coefficients to one another within the same time period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           2020-01  2020-02  2020-03  2020-04  2020-05  \\\n",
      "feature_name                                                             \n",
      "book_id                      0.000    0.000    0.000    0.000    0.000   \n",
      "review_count 2018-01         0.037    0.026    0.027    0.041    0.030   \n",
      "review_count 2018-02         0.036    0.033    0.026    0.057    0.037   \n",
      "review_count 2018-03         0.051    0.031    0.027    0.047    0.034   \n",
      "review_count 2018-04         0.022    0.023    0.027    0.051    0.024   \n",
      "...                            ...      ...      ...      ...      ...   \n",
      "book_author_Nancy Thayer    -0.396    0.186    0.178   -0.417    0.611   \n",
      "book_author_Brad Thor        0.022   -0.083   -0.084    0.021   -0.113   \n",
      "book_author_T.A. White      -0.127    0.128    0.363    0.622    0.317   \n",
      "book_author_Sierra Simone    0.058   -0.133    0.065   -0.221    0.087   \n",
      "book_author_Hazel Gaynor     0.273   -0.199   -0.207   -0.224   -0.269   \n",
      "\n",
      "                           2020-06  2020-07  2020-08  2020-09  2020-10  \\\n",
      "feature_name                                                             \n",
      "book_id                      0.000    0.000    0.000    0.000    0.000   \n",
      "review_count 2018-01         0.037    0.025    0.027    0.027    0.021   \n",
      "review_count 2018-02         0.039    0.027    0.023    0.033    0.026   \n",
      "review_count 2018-03         0.054    0.032    0.033    0.028    0.023   \n",
      "review_count 2018-04         0.027    0.027    0.028    0.029    0.025   \n",
      "...                            ...      ...      ...      ...      ...   \n",
      "book_author_Nancy Thayer     0.073    0.056   -0.310   -0.225   -0.117   \n",
      "book_author_Brad Thor       -0.020   -0.017   -0.096   -0.086    0.021   \n",
      "book_author_T.A. White       0.267    0.196    0.070   -0.120    0.070   \n",
      "book_author_Sierra Simone    0.020   -0.143   -0.176    0.038   -0.073   \n",
      "book_author_Hazel Gaynor    -0.273   -0.180   -0.209   -0.139   -0.067   \n",
      "\n",
      "                           2020-11  \n",
      "feature_name                        \n",
      "book_id                      0.000  \n",
      "review_count 2018-01         0.000  \n",
      "review_count 2018-02         0.000  \n",
      "review_count 2018-03         0.000  \n",
      "review_count 2018-04         0.000  \n",
      "...                            ...  \n",
      "book_author_Nancy Thayer    -0.002  \n",
      "book_author_Brad Thor       -0.001  \n",
      "book_author_T.A. White      -0.002  \n",
      "book_author_Sierra Simone   -0.002  \n",
      "book_author_Hazel Gaynor    -0.002  \n",
      "\n",
      "[2174 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "coefficient_dict = {}\n",
    "\n",
    "for period in time_periods_post:\n",
    "    period_name = period.replace(\"review_count \", \"\")\n",
    "    \n",
    "    model = model_dict.get(period)\n",
    "    coefficients = model.coef_\n",
    "    #intercept = model.intercept_\n",
    "    \n",
    "    coefficient_dict[period_name] = coefficients\n",
    "    \n",
    "coefficient_df = pd.DataFrame.from_dict(coefficient_dict)\n",
    "\n",
    "feature_data = data.copy()\n",
    "\n",
    "for col in feature_data.columns:\n",
    "    if col in time_periods_post:\n",
    "        feature_data.drop(columns = col, inplace = True)\n",
    "        \n",
    "feature_names = feature_data.columns\n",
    "\n",
    "coefficient_df[\"feature_name\"] = feature_names\n",
    "coefficient_df.set_index(\"feature_name\", inplace = True)\n",
    "\n",
    "print(coefficient_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
