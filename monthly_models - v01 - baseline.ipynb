{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process will take all the 2018-2019 periods as features and will use those to predict reviews for each 2020 period. Differences in the overall accuracy of each model as well as shifts in the importance of different features to the model may indicate COVID-related change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import aggregator as ag\n",
    "import monthly_modeler as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_name_review = \"distributed_data_collection/databases/review_data_sample.csv\"\n",
    "data_file_name_book = \"distributed_data_collection/databases/book_data_sample.csv\"\n",
    "\n",
    "#data_file_name_review = \"distributed_data_collection/databases/review_data.csv\"\n",
    "#data_file_name_book = \"distributed_data_collection/databases/book_data.csv\"\n",
    "\n",
    "start_date = datetime.datetime(2018, 1, 1)\n",
    "end_date = datetime.datetime(2020, 9, 30)\n",
    "\n",
    "book_columns = [\"num_reviews\", \"num_ratings\", \"avg_rating\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically, we could test against multiple grains (ie, day, week, month, quarter). However, I am only working with month. I ruled out the quarterly grain because it wouldn't include enough 2020 time periods to observe a trend in model performance over time. Then because the maximum monthly review counts were in the seventies, I didn't feel I could split those further.\n",
    "\n",
    "I want to drop binary feature columns which have a small number of values. The linear regression regularization will do a rigorous feature selection, so this step is mostly to reduce the amount of data that it has to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregator Initiated.\n",
      "Processing Scraper Output...\n",
      "Scraper Output Processed.\n",
      "Aggregating Review Data...\n",
      "Review Data Aggregated.\n",
      "Merging Book Data...\n",
      "Book Data Merged.\n",
      "Applying Sparsity Filter...\n",
      "Dropped 9/33 columns. 24 columns remaining.\n"
     ]
    }
   ],
   "source": [
    "data_aggregator = ag.Aggregator(data_file_name_review, data_file_name_book, book_columns, start_date, end_date, \"month\")\n",
    "data_aggregator.aggregate(\"by_book\")\n",
    "data_aggregator.sparsity_filter(2)\n",
    "\n",
    "time_periods_post = data_aggregator.get_annual_time_periods(2020)\n",
    "data_train, data_test = data_aggregator.get_train_test_split(0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to iterate through: logorithmic transformation, regularization type, and alpha value. For the moment, I am turning logorithmic transformation off. It's pretty clear that it has no impact, and I don't want to keep running it while I experiment with other aspects of the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = [1]\n",
    "regression_types_list = [\"linear\"]\n",
    "is_log_options = [False] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here goes on modeling! We will select the best model for each time period based on MSE. The performance df captures the overall predictiveness of pre-period data on post-period data. We expect to see declines due to concept drift. Sharp dropoffs in performance might suggest larger changes in reading trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_processor = mm.Regression_Processor(data_train, data_test, time_periods_post, regression_types_list, is_log_options, alpha_list)\n",
    "performance_df, model_dict = regression_processor.get_optimal_models()\n",
    "\n",
    "print(performance_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where it's really at! Understanding what features are most important to each model can help us understand the drivers of reading in each period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficient_df = regression_processor.get_coefficient_df()\n",
    "coefficient_df = regression_processor.print_top_coefficients()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want to understand the relative importance of each historical period. Even if it isn't the main driver, it should give some indication of whether trends are changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_period_importance = regression_processor.get_pre_period_importance()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
